# AI_music_generation

Development of a new music dataset, and training of a diffusion model for symbolic music generation. The full report in the form of an IEEE paper (`Diffusion_Music_Generation.pdf`), as well as the project's poster (`Poster_Imitating_Bach.pdf`) and power point presentation (`Imitating_Bach_Presentation.pptx`) are available as well.

## MIDI Dataset

File `midi_dataset.zip` contains keyboard compositions by Bach in the form of MIDI files. Noteworthy works included are the inventions and the sinfonias.

## Binary Image Dataset

To create a binary image dataset, which will be used for training, open the notebook `midi2binim_dataset.ipynb` and follow the instructions. The dataset that we used is `dataset.zip` and it includes the first book of "The Well Tempered Clavier", augmented with different techniques.

## Model

To train your model, open the notebook `train_model.ipynb`, and follow the instructions there. Our pretrained model is available in the file `checkpoint.pth`.

## Unconditional Generation & Infilling

The corresponding notebooks for each task are `generate.ipynb` and `infilling.ipynb`. To run them, a pretrained model will be needed.

## Back to MIDI

Both `generate.ipynb` and `infilling.ipynb` produce samples in the form of binary images. To convert them to MIDI files open the notebook `binim2midi.ipynb` and follow the instructions.

## Results

Some samples generated by our model can be found in the zip file `midi_samples.zip`.
