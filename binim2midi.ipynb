{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# From Image Samples to MIDI Files\n",
        "\n",
        "This notebook presents an implementation of a function designed to process a compressed file named samples.zip. This compressed file contains a directory consisting of binary images, samples produced by the model. The output of this function is intended to result in a compressed file named midi_samples.zip, containing the MIDI files corresponding to the given samples.\n",
        "\n",
        "Again, we acknowledge that a significant portion of the development effort invested in this notebook is derived from [here](https://medium.com/analytics-vidhya/convert-midi-file-to-numpy-array-in-python-7d00531890c)."
      ],
      "metadata": {
        "id": "x8UnfS6amquG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03nW1NhYVOEO"
      },
      "outputs": [],
      "source": [
        "pip install mido"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import mido\n",
        "import string\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "from torchvision import transforms as T,utils"
      ],
      "metadata": {
        "id": "FLo2TNK8WLSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip samples.zip"
      ],
      "metadata": {
        "id": "YvoJPMqoZLB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary Function\n",
        "\n",
        "The following function is used to convert a binary array to a MIDI file. The function has been adapted for our purposes. For further details on what exactly it does, interested readers are directed to consult the original work [here](https://medium.com/analytics-vidhya/convert-midi-file-to-numpy-array-in-python-7d00531890c)."
      ],
      "metadata": {
        "id": "x2Qc98oAoHxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def arry2mid(ary, tempo=500000, step=60):\n",
        "  # get the difference\n",
        "  new_ary = np.concatenate([np.array([[0] * 88]), np.array(ary)], axis=0)\n",
        "  changes = new_ary[1:] - new_ary[:-1]\n",
        "  # create a midi file with an empty track\n",
        "  mid_new = mido.MidiFile()\n",
        "  track = mido.MidiTrack()\n",
        "  mid_new.tracks.append(track)\n",
        "  track.append(mido.MetaMessage('set_tempo', tempo=tempo, time=0))\n",
        "  # add difference in the empty track\n",
        "  last_time = 0\n",
        "  for ch in changes:\n",
        "    if set(ch) == {0}:  # no change\n",
        "      last_time += step\n",
        "    else:\n",
        "      on_notes = np.where(ch > 0)[0]\n",
        "      on_notes_vol = ch[on_notes]\n",
        "      off_notes = np.where(ch < 0)[0]\n",
        "      first_ = True\n",
        "      for n in off_notes:\n",
        "        new_time = last_time if first_ else 0\n",
        "        track.append(mido.Message('note_off', note=n + 21, velocity=0, time=new_time))\n",
        "        first_ = False\n",
        "      for n, v in zip(on_notes, on_notes_vol):\n",
        "        new_time = last_time if first_ else 0\n",
        "        track.append(mido.Message('note_on', note=n + 21, velocity=60, time=new_time))\n",
        "        first_ = False\n",
        "\n",
        "      last_time = step\n",
        "  return mid_new"
      ],
      "metadata": {
        "id": "zM7Q1hVdXQYW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function ```convert_samples```\n",
        "\n",
        "The function that converts the binary image samples to MIDI files. The only parameter **step** is used to determine the number of ticks per demisemiquaver - or the thirty-second note. Be aware that this parameter *must* have the same value with the parameter step used to generate the image dataset. Default value is set to 60."
      ],
      "metadata": {
        "id": "WDE2u0rpoYn5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_samples(step=60):\n",
        "  transform = T.Compose([T.ToTensor()])\n",
        "  os.makedirs('midi_samples')\n",
        "  for image in os.listdir('samples'):\n",
        "    f = os.path.join('samples', image)\n",
        "    img = Image.open(f)\n",
        "    img=transform(img)\n",
        "\n",
        "    mid_new = arry2mid(ary=img[0],step=step)\n",
        "    mid_new.save('midi_samples/'+image[0:len(image)-4]+'.mid')\n",
        "\n",
        "  !zip -r '/content/midi_samples.zip' './midi_samples'"
      ],
      "metadata": {
        "id": "0YVV8PiBWma-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}